{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import applicants\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim\n",
    "from numpy.random import rand\n",
    "from itertools import combinations\n",
    "import time\n",
    "import operator\n",
    "import re\n",
    "import os\n",
    "import topic_model, dataio, d2v_utils\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#df_users = applicants.get_applicant_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting job posting data...\n",
      "- Time: 0.601379871368\n",
      "\n",
      "df_jobs shape: (9015, 6)\n"
     ]
    }
   ],
   "source": [
    "import jobs\n",
    "\n",
    "df_jobs = jobs.get_job_posting_data()\n",
    "\n",
    "# Use a subset of data\n",
    "df_jobs = df_jobs[15000:]\n",
    "df_jobs.reset_index(inplace=True)\n",
    "\n",
    "print('df_jobs shape: %s' % str(df_jobs.shape))\n",
    "\n",
    "docs = df_jobs.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params to build the vocab and topics\n",
    "min_df = 50\n",
    "max_df = .1\n",
    "k_topics = 18\n",
    "max_vocab_size = 10000\n",
    "ngram_range=([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents to process: 9015\n",
      "\n",
      "Extracting Vectorizer features...\n",
      "- Time: 11.074s.\n",
      "\n",
      "Fitting NMF model with LocalwiseVectorizer features, n_samples=9015 and n_features=10000...\n",
      "- Time: 3.047s.\n",
      "\n",
      "Reconstruction mse: 0.000321\n",
      "Topic 0: program, organization, community, support, development, project, report, relationship, meeting, degree, social, director, resource, partner, management\n",
      "\n",
      "Topic 1: restaurant, food, dining, wine, chef, guest, hospitality, cuisine, fast, fine, year, beer, menu, paced, dinner\n",
      "\n",
      "Topic 2: child, teacher, school, teaching, age, preschool, classroom, early, class, student, childhood, curriculum, program, parent, center\n",
      "\n",
      "Topic 3: customer, sale, retail, store, product, associate, service, business, brand, weekend, motivated, industry, growing, grow, fashion\n",
      "\n",
      "Topic 4: standard, lift, equipment, procedure, guest, clean, safety, area, cleaning, stand, ensure, item, assist, perform, product\n",
      "\n",
      "Topic 5: sitter, babysitter, babysitting, hunt, decide, nanny, tap, connected, fee, rate, app, cut, started, verify, accept\n",
      "\n",
      "Topic 6: test, pas, drug, exam, clearance, check, fingerprint, negative, authorized, blog, criminal, don, score, testing, tutor\n",
      "\n",
      "Topic 7: server, bartender, host, bar, bussers, hostess, position, tip, busser, wine, runner, night, cocktail, stop, interview\n",
      "\n",
      "Topic 8: cook, line, prep, kitchen, cooking, pizza, food, grill, restaurant, position, chef, wood, knife, breakfast, pizzeria\n",
      "\n",
      "Topic 9: phone, office, task, excel, word, computer, call, multi, administrative, entry, microsoft, filing, assistant, answering, written\n",
      "\n",
      "Topic 10: driver, license, valid, driving, record, vehicle, delivery, clean, california, truck, car, service, dmv, home, bay\n",
      "\n",
      "Topic 11: tutor, student, tutoring, educator, chemistry, math, parent, teaching, study, home, science, algebra, pedagogy, subject, academically\n",
      "\n",
      "Topic 12: salon, stylist, hair, clientele, licensed, spa, client, rent, commission, nail, located, cosmetology, station, beauty, service\n",
      "\n",
      "Topic 13: coffee, cafe, barista, cashier, drink, sandwich, food, customer, pastry, fast, espresso, bakery, paced, morning, counter\n",
      "\n",
      "Topic 14: state, spread, oil, organizer, heard, gas, citizen, protection, calling, water, central, sacramento, continue, campaign, voice\n",
      "\n",
      "Topic 15: dishwasher, prep, kitchen, restaurant, dish, busser, bussers, shift, clean, hard, washing, dishwashing, fast, hill, sunday\n",
      "\n",
      "Topic 16: instructor, challenge, student, session, supervisor, class, stem, transformation, incorporated, rise, feed, faced, elementary, seed, middle\n",
      "\n",
      "Topic 17: applying, visit, business, website, position, studio, furniture, north, information, subject, wanted, union, west, hair, college\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tm = topic_model.TopicModeller(model_type='NMF', vectorizer_type='localwise')\n",
    "tm.fit(docs, max_vocab_size=max_vocab_size, \n",
    "             min_df=min_df, k_topics=k_topics,\n",
    "             ngram_range=ngram_range)\n",
    "du = d2v_utils.D2V_Utils(tm.vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "topic_model.py:196: RuntimeWarning: invalid value encountered in divide\n",
      "  probs = (topic_weights / topic_weights.sum())\n"
     ]
    }
   ],
   "source": [
    "top_topics, top_topic_weights = tm.get_top_topics_and_topic_probs()\n",
    "\n",
    "df_jobs['top_topic'] = top_topics\n",
    "df_jobs['top_topic_weight'] = top_topic_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing docs...\n",
      "- Time: 0.000716924667358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[u'madison',\n",
       "  u'opened',\n",
       "  u'family',\n",
       "  u'restaurant',\n",
       "  u'sacramento',\n",
       "  u'hard',\n",
       "  u'miracle',\n",
       "  u'dining',\n",
       "  u'kabab',\n",
       "  u'cook',\n",
       "  u'ca95841',\n",
       "  u'line',\n",
       "  u'bigger',\n",
       "  u'kitchen']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_idx = 100\n",
    "tokens = du.get_tokenized_docs([docs[doc_idx]])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Essy's miracle kabab\\n\\nOur restaurants are a high energy, fun and family-friendly dining environment for everyone to enjoy. We will make bigger team now\\n\\nWe are opened restaurant 7 years\\n\\nWe looking for worked in kitchen\\n\\nat least 1 year full time work\\n\\nAnd reliable and hard working as line cook\\n\\n**Please only text me:**\\n\\nEssy\\n\\n(916) 7280314\\n\\n5207 Madison ave Sacramento CA95841\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[doc_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = ['fast', 'cook','dishwasher','runner','bringing',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preProcess(s):\n",
    "#     s = ' '.join(titles)\n",
    "    for t in titles:\n",
    "        if t in s:\n",
    "            s = s + str(' '+t+' ') * 3\n",
    "    return s\n",
    "\n",
    "class myvec(TfidfVectorizer):\n",
    "    '''\n",
    "    http://scikit-learn.org/dev/modules/feature_extraction.html#vectorizing-a-large-text-corpus-with-the-hashing-trick\n",
    "            self.vectorizer = TfidfVectorizer(token_pattern=get_token_pattern(),\n",
    "                                              min_df=min_df,\n",
    "                                              max_features=max_vocab_size,\n",
    "                                              stop_words=get_stop_words(),\n",
    "                                              ngram_range=ngram_range)\n",
    "    '''\n",
    "    def __init__(self, inflection_form='lemmer', max_features=5000, \n",
    "                                                 min_df=10,\n",
    "                                                 ngram_range=ngram_range):\n",
    "        super(myvec, self).__init__(max_features=max_features,\n",
    "                                                  min_df=min_df,\n",
    "                                                  ngram_range=ngram_range)\n",
    "        self.inflection_form = inflection_form.lower()\n",
    "        \n",
    "#     def build_preprocessor(self):\n",
    "#         preprocessor = super(myvec, self).build_preprocessor()\n",
    "#         return lambda doc: preProcess(preprocessor(doc))\n",
    "\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(myvec, self).build_analyzer()\n",
    "        sw = topic_model.get_stop_words()\n",
    "        pattern = re.compile(topic_model.get_token_pattern())\n",
    "        if self.inflection_form == 'lemmer':\n",
    "            lemmer = WordNetLemmatizer()\n",
    "            return lambda doc:(lemmer.lemmatize(w) for w in list(set(analyzer(doc)) - set(sw)) \n",
    "                               if pattern.match(w) if len(set(w.split()).intersection(sw)) == 0)\n",
    "        else:\n",
    "            stemmer = PorterStemmer()\n",
    "            return lambda doc:(stemmer.stem(w) for w in list(set(analyzer(doc)) - set(sw)) if pattern.match(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Time: 1.03492379189\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = myvec(preprocessor=preProcess)\n",
    "vectorizer = myvec()\n",
    "t1 = time.time()\n",
    "tfidf_matrix = vectorizer.fit_transform(docs[:1000])\n",
    "print '- Time: %s' % (time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitchen 0.28550024922102973\n",
      "dining 0.36363840744357084\n",
      "cook 0.3074904194290135\n",
      "restaurant 0.4945824161470926\n",
      "line 0.27200367901314\n",
      "year 0.19868883744810542\n",
      "family 0.2791851077368607\n",
      "opened 0.4103634959386376\n",
      "hard 0.2954468026903001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = doc_idx\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_index = tfidf_matrix[doc,:].nonzero()[1]\n",
    "tfidf_scores = zip(feature_index, [tfidf_matrix[doc, x] for x in feature_index])\n",
    "\n",
    "#print\n",
    "for w, s in [(feature_names[i], s) for (i, s) in tfidf_scores]:\n",
    "    print w, s\n",
    "\n",
    "# print feature_names\n",
    "# print len(vectorizer.vocabulary_.keys())\n",
    "vectorizer.vocabulary_['busser']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1844,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.idf_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
