{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec, Word2Vec, Doc2Vec, KeyedVectors\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument, LabeledSentence\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import jobs\n",
    "import topic_model\n",
    "\n",
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting job posting data...\n",
      "- Time: 0.598479032516\n",
      "\n",
      "(24015, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<topic_model.TokenGenerator_skl instance at 0x7fdaaa4b15f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get job postings, vectorizer, token generator\n",
    "df_jobs = jobs.get_job_posting_data()\n",
    "print df_jobs.shape\n",
    "docs = df_jobs.description[0:20000]\n",
    "docs = df_jobs.description\n",
    "\n",
    "min_df=20\n",
    "max_vocab_size=5000\n",
    "dim_size=500\n",
    "ngram_range=(1, 1)\n",
    "\n",
    "vectorizer = TfidfVectorizer(token_pattern=topic_model.get_token_pattern(),\n",
    "                                              min_df=min_df,\n",
    "                                              max_features=max_vocab_size,\n",
    "                                              stop_words=topic_model.get_stop_words(),\n",
    "                                              ngram_range=ngram_range)\n",
    "\n",
    "docgen = topic_model.TokenGenerator_skl(vectorizer, docs, topic_model.get_stop_words())\n",
    "docgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.word2vec.Word2Vec"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from gensim.models.word2vec import Word2Vec as w2v2\n",
    "from gensim.models import Word2Vec as w2v\n",
    "w2v_model = w2v()\n",
    "type(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:21:07,053 : INFO : collecting all words and their counts\n",
      "2018-01-08 01:21:07,056 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-01-08 01:21:07,164 : INFO : pruned out 0 tokens with count <=1 (before 5001, after 5001)\n",
      "2018-01-08 01:21:07,172 : INFO : pruned out 1999 tokens with count <=2 (before 5004, after 3005)\n",
      "2018-01-08 01:21:07,252 : INFO : pruned out 2075 tokens with count <=3 (before 5010, after 2935)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:21:07,327 : INFO : pruned out 2204 tokens with count <=4 (before 5030, after 2826)\n",
      "2018-01-08 01:21:07,423 : INFO : pruned out 2181 tokens with count <=5 (before 5025, after 2844)\n",
      "2018-01-08 01:21:07,499 : INFO : pruned out 2272 tokens with count <=6 (before 5022, after 2750)\n",
      "2018-01-08 01:21:07,584 : INFO : pruned out 2335 tokens with count <=7 (before 5025, after 2690)\n",
      "2018-01-08 01:21:07,680 : INFO : pruned out 2267 tokens with count <=8 (before 5010, after 2743)\n",
      "2018-01-08 01:21:07,830 : INFO : pruned out 2195 tokens with count <=9 (before 5004, after 2809)\n",
      "2018-01-08 01:21:07,915 : INFO : pruned out 2249 tokens with count <=10 (before 5002, after 2753)\n",
      "2018-01-08 01:21:07,986 : INFO : pruned out 2323 tokens with count <=11 (before 5030, after 2707)\n",
      "2018-01-08 01:21:08,056 : INFO : pruned out 2367 tokens with count <=12 (before 5030, after 2663)\n",
      "2018-01-08 01:21:08,126 : INFO : pruned out 2472 tokens with count <=13 (before 5091, after 2619)\n",
      "2018-01-08 01:21:08,199 : INFO : pruned out 2415 tokens with count <=14 (before 5002, after 2587)\n",
      "2018-01-08 01:21:08,270 : INFO : pruned out 2441 tokens with count <=15 (before 5001, after 2560)\n",
      "2018-01-08 01:21:08,360 : INFO : pruned out 2490 tokens with count <=16 (before 5036, after 2546)\n",
      "2018-01-08 01:21:08,433 : INFO : pruned out 2474 tokens with count <=17 (before 5001, after 2527)\n",
      "2018-01-08 01:21:08,533 : INFO : pruned out 2487 tokens with count <=18 (before 5001, after 2514)\n",
      "2018-01-08 01:21:08,620 : INFO : pruned out 2504 tokens with count <=19 (before 5003, after 2499)\n",
      "2018-01-08 01:21:08,707 : INFO : pruned out 2528 tokens with count <=20 (before 5018, after 2490)\n",
      "2018-01-08 01:21:08,789 : INFO : pruned out 2529 tokens with count <=21 (before 5009, after 2480)\n",
      "2018-01-08 01:21:09,040 : INFO : pruned out 2456 tokens with count <=22 (before 5008, after 2552)\n",
      "2018-01-08 01:21:09,156 : INFO : pruned out 2449 tokens with count <=23 (before 5001, after 2552)\n",
      "2018-01-08 01:21:09,298 : INFO : pruned out 2420 tokens with count <=24 (before 5030, after 2610)\n",
      "2018-01-08 01:21:09,382 : INFO : pruned out 2400 tokens with count <=25 (before 5002, after 2602)\n",
      "2018-01-08 01:21:09,488 : INFO : pruned out 2385 tokens with count <=26 (before 5012, after 2627)\n",
      "2018-01-08 01:21:09,570 : INFO : pruned out 2391 tokens with count <=27 (before 5012, after 2621)\n",
      "2018-01-08 01:21:09,644 : INFO : pruned out 2401 tokens with count <=28 (before 5011, after 2610)\n",
      "2018-01-08 01:21:09,714 : INFO : pruned out 2411 tokens with count <=29 (before 5017, after 2606)\n",
      "2018-01-08 01:21:09,789 : INFO : pruned out 2411 tokens with count <=30 (before 5014, after 2603)\n",
      "2018-01-08 01:21:09,877 : INFO : pruned out 2419 tokens with count <=31 (before 5018, after 2599)\n",
      "2018-01-08 01:21:09,961 : INFO : pruned out 2414 tokens with count <=32 (before 5002, after 2588)\n",
      "2018-01-08 01:21:10,039 : INFO : pruned out 2444 tokens with count <=33 (before 5023, after 2579)\n",
      "2018-01-08 01:21:10,138 : INFO : pruned out 2439 tokens with count <=34 (before 5013, after 2574)\n",
      "2018-01-08 01:21:10,219 : INFO : pruned out 2442 tokens with count <=35 (before 5007, after 2565)\n",
      "2018-01-08 01:21:10,328 : INFO : pruned out 2447 tokens with count <=36 (before 5010, after 2563)\n",
      "2018-01-08 01:21:10,434 : INFO : pruned out 2460 tokens with count <=37 (before 5019, after 2559)\n",
      "2018-01-08 01:21:10,514 : INFO : pruned out 2463 tokens with count <=38 (before 5019, after 2556)\n",
      "2018-01-08 01:21:10,593 : INFO : pruned out 2487 tokens with count <=39 (before 5036, after 2549)\n",
      "2018-01-08 01:21:10,675 : INFO : pruned out 2480 tokens with count <=40 (before 5021, after 2541)\n",
      "2018-01-08 01:21:10,770 : INFO : pruned out 2475 tokens with count <=41 (before 5010, after 2535)\n",
      "2018-01-08 01:21:10,840 : INFO : pruned out 2486 tokens with count <=42 (before 5012, after 2526)\n",
      "2018-01-08 01:21:10,917 : INFO : pruned out 2491 tokens with count <=43 (before 5011, after 2520)\n",
      "2018-01-08 01:21:10,983 : INFO : pruned out 2507 tokens with count <=44 (before 5016, after 2509)\n",
      "2018-01-08 01:21:11,070 : INFO : pruned out 2516 tokens with count <=45 (before 5020, after 2504)\n",
      "2018-01-08 01:21:11,257 : INFO : pruned out 2470 tokens with count <=46 (before 5005, after 2535)\n",
      "2018-01-08 01:21:11,360 : INFO : pruned out 2479 tokens with count <=47 (before 5009, after 2530)\n",
      "2018-01-08 01:21:11,488 : INFO : PROGRESS: at sentence #10000, processed 1053228 words, keeping 4872 word types\n",
      "2018-01-08 01:21:11,543 : INFO : pruned out 2443 tokens with count <=48 (before 5003, after 2560)\n",
      "2018-01-08 01:21:11,661 : INFO : pruned out 2460 tokens with count <=49 (before 5016, after 2556)\n",
      "2018-01-08 01:21:11,759 : INFO : pruned out 2455 tokens with count <=50 (before 5007, after 2552)\n",
      "2018-01-08 01:21:11,884 : INFO : pruned out 2460 tokens with count <=51 (before 5007, after 2547)\n",
      "2018-01-08 01:21:11,992 : INFO : pruned out 2466 tokens with count <=52 (before 5011, after 2545)\n",
      "2018-01-08 01:21:12,088 : INFO : pruned out 2466 tokens with count <=53 (before 5004, after 2538)\n",
      "2018-01-08 01:21:12,180 : INFO : pruned out 2473 tokens with count <=54 (before 5008, after 2535)\n",
      "2018-01-08 01:21:12,267 : INFO : pruned out 2475 tokens with count <=55 (before 5006, after 2531)\n",
      "2018-01-08 01:21:12,352 : INFO : pruned out 2485 tokens with count <=56 (before 5013, after 2528)\n",
      "2018-01-08 01:21:12,436 : INFO : pruned out 2479 tokens with count <=57 (before 5005, after 2526)\n",
      "2018-01-08 01:21:12,510 : INFO : pruned out 2478 tokens with count <=58 (before 5004, after 2526)\n",
      "2018-01-08 01:21:12,590 : INFO : pruned out 2485 tokens with count <=59 (before 5007, after 2522)\n",
      "2018-01-08 01:21:12,713 : INFO : pruned out 2504 tokens with count <=60 (before 5023, after 2519)\n",
      "2018-01-08 01:21:12,798 : INFO : pruned out 2489 tokens with count <=61 (before 5004, after 2515)\n",
      "2018-01-08 01:21:12,881 : INFO : pruned out 2492 tokens with count <=62 (before 5004, after 2512)\n",
      "2018-01-08 01:21:12,972 : INFO : pruned out 2491 tokens with count <=63 (before 5002, after 2511)\n",
      "2018-01-08 01:21:13,075 : INFO : pruned out 2494 tokens with count <=64 (before 5004, after 2510)\n",
      "2018-01-08 01:21:13,175 : INFO : pruned out 2506 tokens with count <=65 (before 5015, after 2509)\n",
      "2018-01-08 01:21:13,298 : INFO : pruned out 2494 tokens with count <=66 (before 5003, after 2509)\n",
      "2018-01-08 01:21:13,382 : INFO : pruned out 2506 tokens with count <=67 (before 5014, after 2508)\n",
      "2018-01-08 01:21:13,462 : INFO : pruned out 2507 tokens with count <=68 (before 5013, after 2506)\n",
      "2018-01-08 01:21:13,534 : INFO : pruned out 2497 tokens with count <=69 (before 5002, after 2505)\n",
      "2018-01-08 01:21:13,602 : INFO : pruned out 2497 tokens with count <=70 (before 5001, after 2504)\n",
      "2018-01-08 01:21:13,671 : INFO : pruned out 2497 tokens with count <=71 (before 5001, after 2504)\n",
      "2018-01-08 01:21:13,747 : INFO : pruned out 2501 tokens with count <=72 (before 5003, after 2502)\n",
      "2018-01-08 01:21:13,836 : INFO : pruned out 2502 tokens with count <=73 (before 5002, after 2500)\n",
      "2018-01-08 01:21:13,926 : INFO : pruned out 2580 tokens with count <=74 (before 5078, after 2498)\n",
      "2018-01-08 01:21:14,030 : INFO : pruned out 2511 tokens with count <=75 (before 5007, after 2496)\n",
      "2018-01-08 01:21:14,121 : INFO : pruned out 2507 tokens with count <=76 (before 5002, after 2495)\n",
      "2018-01-08 01:21:14,212 : INFO : pruned out 2518 tokens with count <=77 (before 5011, after 2493)\n",
      "2018-01-08 01:21:14,308 : INFO : pruned out 2536 tokens with count <=78 (before 5027, after 2491)\n",
      "2018-01-08 01:21:14,433 : INFO : pruned out 2529 tokens with count <=79 (before 5020, after 2491)\n",
      "2018-01-08 01:21:14,537 : INFO : pruned out 2540 tokens with count <=80 (before 5030, after 2490)\n",
      "2018-01-08 01:21:14,628 : INFO : pruned out 2546 tokens with count <=81 (before 5035, after 2489)\n",
      "2018-01-08 01:21:14,725 : INFO : pruned out 2532 tokens with count <=82 (before 5021, after 2489)\n",
      "2018-01-08 01:21:14,805 : INFO : pruned out 2526 tokens with count <=83 (before 5015, after 2489)\n",
      "2018-01-08 01:21:14,878 : INFO : pruned out 2519 tokens with count <=84 (before 5008, after 2489)\n",
      "2018-01-08 01:21:14,941 : INFO : pruned out 2513 tokens with count <=85 (before 5002, after 2489)\n",
      "2018-01-08 01:21:15,014 : INFO : pruned out 2534 tokens with count <=86 (before 5023, after 2489)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:21:15,100 : INFO : pruned out 2520 tokens with count <=87 (before 5008, after 2488)\n",
      "2018-01-08 01:21:15,198 : INFO : pruned out 2524 tokens with count <=88 (before 5011, after 2487)\n",
      "2018-01-08 01:21:15,275 : INFO : pruned out 2517 tokens with count <=89 (before 5001, after 2484)\n",
      "2018-01-08 01:21:15,360 : INFO : pruned out 2527 tokens with count <=90 (before 5008, after 2481)\n",
      "2018-01-08 01:21:15,507 : INFO : pruned out 2527 tokens with count <=91 (before 5007, after 2480)\n",
      "2018-01-08 01:21:15,620 : INFO : pruned out 2577 tokens with count <=92 (before 5057, after 2480)\n",
      "2018-01-08 01:21:15,697 : INFO : pruned out 2530 tokens with count <=93 (before 5007, after 2477)\n",
      "2018-01-08 01:21:15,771 : INFO : PROGRESS: at sentence #20000, processed 2076095 words, keeping 4777 word types\n",
      "2018-01-08 01:21:15,783 : INFO : pruned out 2529 tokens with count <=94 (before 5006, after 2477)\n",
      "2018-01-08 01:21:15,853 : INFO : pruned out 2551 tokens with count <=95 (before 5027, after 2476)\n",
      "2018-01-08 01:21:15,930 : INFO : pruned out 2530 tokens with count <=96 (before 5003, after 2473)\n",
      "2018-01-08 01:21:16,013 : INFO : pruned out 2529 tokens with count <=97 (before 5002, after 2473)\n",
      "2018-01-08 01:21:16,091 : INFO : pruned out 2542 tokens with count <=98 (before 5015, after 2473)\n",
      "2018-01-08 01:21:16,155 : INFO : pruned out 2532 tokens with count <=99 (before 5001, after 2469)\n",
      "2018-01-08 01:21:16,259 : INFO : pruned out 2539 tokens with count <=100 (before 5004, after 2465)\n",
      "2018-01-08 01:21:16,387 : INFO : pruned out 2539 tokens with count <=101 (before 5003, after 2464)\n",
      "2018-01-08 01:21:16,480 : INFO : pruned out 2542 tokens with count <=102 (before 5006, after 2464)\n",
      "2018-01-08 01:21:16,570 : INFO : pruned out 2542 tokens with count <=103 (before 5006, after 2464)\n",
      "2018-01-08 01:21:16,663 : INFO : pruned out 2544 tokens with count <=104 (before 5006, after 2462)\n",
      "2018-01-08 01:21:16,801 : INFO : pruned out 2539 tokens with count <=105 (before 5001, after 2462)\n",
      "2018-01-08 01:21:16,911 : INFO : pruned out 2541 tokens with count <=106 (before 5002, after 2461)\n",
      "2018-01-08 01:21:16,997 : INFO : pruned out 2548 tokens with count <=107 (before 5006, after 2458)\n",
      "2018-01-08 01:21:17,080 : INFO : pruned out 2549 tokens with count <=108 (before 5007, after 2458)\n",
      "2018-01-08 01:21:17,150 : INFO : pruned out 2552 tokens with count <=109 (before 5010, after 2458)\n",
      "2018-01-08 01:21:17,230 : INFO : pruned out 2551 tokens with count <=110 (before 5009, after 2458)\n",
      "2018-01-08 01:21:17,306 : INFO : pruned out 2572 tokens with count <=111 (before 5027, after 2455)\n",
      "2018-01-08 01:21:17,382 : INFO : pruned out 2565 tokens with count <=112 (before 5019, after 2454)\n",
      "2018-01-08 01:21:17,421 : INFO : collected 3877 word types from a corpus of 2464662 raw words and 24015 sentences\n",
      "2018-01-08 01:21:17,422 : INFO : Loading a fresh vocabulary\n",
      "2018-01-08 01:21:17,442 : INFO : min_count=20 retains 2454 unique words (63% of original 3877, drops 1423)\n",
      "2018-01-08 01:21:17,444 : INFO : min_count=20 leaves 1952712 word corpus (99% of original 1954437, drops 1725)\n",
      "2018-01-08 01:21:17,452 : INFO : deleting the raw counts dictionary of 3877 items\n",
      "2018-01-08 01:21:17,454 : INFO : sample=0.001 downsamples 14 most-common words\n",
      "2018-01-08 01:21:17,457 : INFO : downsampling leaves estimated 1936901 word corpus (99.2% of prior 1952712)\n",
      "2018-01-08 01:21:17,458 : INFO : estimated required memory for 2454 words and 500 dimensions: 11043000 bytes\n",
      "2018-01-08 01:21:17,467 : INFO : resetting layer weights\n",
      "2018-01-08 01:21:17,509 : INFO : training model with 3 workers on 2454 vocabulary and 500 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:21:18,546 : INFO : PROGRESS: at 0.50% examples, 54645 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:19,616 : INFO : PROGRESS: at 1.16% examples, 60876 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:20,653 : INFO : PROGRESS: at 2.00% examples, 65707 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:21,705 : INFO : PROGRESS: at 2.78% examples, 66257 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:22,849 : INFO : PROGRESS: at 3.48% examples, 66243 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:23,810 : INFO : PROGRESS: at 4.08% examples, 67439 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:24,830 : INFO : PROGRESS: at 4.90% examples, 67484 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:25,942 : INFO : PROGRESS: at 5.76% examples, 67272 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:27,114 : INFO : PROGRESS: at 6.54% examples, 66688 words/s, in_qsize 0, out_qsize 1\n",
      "2018-01-08 01:21:28,235 : INFO : PROGRESS: at 7.36% examples, 66889 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:29,301 : INFO : PROGRESS: at 8.06% examples, 67529 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:30,329 : INFO : PROGRESS: at 8.47% examples, 67514 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:31,406 : INFO : PROGRESS: at 9.12% examples, 67375 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:32,441 : INFO : PROGRESS: at 9.89% examples, 67392 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:33,478 : INFO : PROGRESS: at 10.75% examples, 67427 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:34,594 : INFO : PROGRESS: at 11.53% examples, 67573 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:35,609 : INFO : PROGRESS: at 12.30% examples, 67646 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:36,629 : INFO : PROGRESS: at 13.08% examples, 67291 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:37,637 : INFO : PROGRESS: at 13.74% examples, 67370 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:38,721 : INFO : PROGRESS: at 14.43% examples, 67273 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:39,773 : INFO : PROGRESS: at 15.43% examples, 67538 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:40,809 : INFO : PROGRESS: at 16.00% examples, 67251 words/s, in_qsize 0, out_qsize 1\n",
      "2018-01-08 01:21:41,865 : INFO : PROGRESS: at 16.71% examples, 67548 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:42,957 : INFO : PROGRESS: at 17.65% examples, 67394 words/s, in_qsize 0, out_qsize 1\n",
      "2018-01-08 01:21:43,933 : INFO : PROGRESS: at 18.32% examples, 67518 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:44,957 : INFO : PROGRESS: at 18.96% examples, 67572 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:46,053 : INFO : PROGRESS: at 19.75% examples, 67406 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:21:47,063 : INFO : PROGRESS: at 20.48% examples, 67531 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:48,345 : INFO : PROGRESS: at 21.14% examples, 67028 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:49,381 : INFO : PROGRESS: at 21.95% examples, 67301 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:50,551 : INFO : PROGRESS: at 22.81% examples, 67280 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:51,660 : INFO : PROGRESS: at 23.57% examples, 67470 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:52,693 : INFO : PROGRESS: at 24.17% examples, 67603 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:53,885 : INFO : PROGRESS: at 25.04% examples, 67297 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:54,933 : INFO : PROGRESS: at 25.93% examples, 67506 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:55,966 : INFO : PROGRESS: at 26.65% examples, 67460 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:57,157 : INFO : PROGRESS: at 27.50% examples, 67372 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:58,259 : INFO : PROGRESS: at 28.09% examples, 67290 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:21:59,311 : INFO : PROGRESS: at 28.57% examples, 67451 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:00,394 : INFO : PROGRESS: at 29.28% examples, 67576 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:01,477 : INFO : PROGRESS: at 30.13% examples, 67504 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:02,573 : INFO : PROGRESS: at 30.87% examples, 67257 words/s, in_qsize 0, out_qsize 1\n",
      "2018-01-08 01:22:03,710 : INFO : PROGRESS: at 31.60% examples, 67295 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:04,725 : INFO : PROGRESS: at 32.45% examples, 67310 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:05,771 : INFO : PROGRESS: at 33.25% examples, 67304 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:06,885 : INFO : PROGRESS: at 33.96% examples, 67347 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:07,981 : INFO : PROGRESS: at 34.75% examples, 67286 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:09,061 : INFO : PROGRESS: at 35.60% examples, 67217 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:10,250 : INFO : PROGRESS: at 36.27% examples, 67196 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:11,274 : INFO : PROGRESS: at 37.07% examples, 67197 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:12,370 : INFO : PROGRESS: at 37.95% examples, 67282 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:13,413 : INFO : PROGRESS: at 38.62% examples, 67286 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:14,432 : INFO : PROGRESS: at 39.21% examples, 67196 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:22:15,497 : INFO : PROGRESS: at 40.09% examples, 67145 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:16,613 : INFO : PROGRESS: at 40.70% examples, 67099 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:17,657 : INFO : PROGRESS: at 41.43% examples, 67259 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:18,678 : INFO : PROGRESS: at 42.29% examples, 67276 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:19,680 : INFO : PROGRESS: at 42.92% examples, 67194 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:20,871 : INFO : PROGRESS: at 43.65% examples, 67254 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:21,986 : INFO : PROGRESS: at 44.41% examples, 67333 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:23,109 : INFO : PROGRESS: at 45.43% examples, 67360 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:24,183 : INFO : PROGRESS: at 46.18% examples, 67316 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:25,285 : INFO : PROGRESS: at 46.92% examples, 67350 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:26,285 : INFO : PROGRESS: at 47.77% examples, 67381 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:27,326 : INFO : PROGRESS: at 48.24% examples, 67390 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:28,365 : INFO : PROGRESS: at 48.67% examples, 67393 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:29,393 : INFO : PROGRESS: at 49.33% examples, 67431 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:30,413 : INFO : PROGRESS: at 50.19% examples, 67429 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:31,447 : INFO : PROGRESS: at 50.89% examples, 67327 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:32,554 : INFO : PROGRESS: at 51.65% examples, 67378 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:33,704 : INFO : PROGRESS: at 52.59% examples, 67373 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:34,768 : INFO : PROGRESS: at 53.46% examples, 67451 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:35,827 : INFO : PROGRESS: at 54.08% examples, 67434 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:36,966 : INFO : PROGRESS: at 54.91% examples, 67346 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:38,130 : INFO : PROGRESS: at 55.80% examples, 67365 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:39,193 : INFO : PROGRESS: at 56.36% examples, 67325 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:40,290 : INFO : PROGRESS: at 57.32% examples, 67358 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:41,401 : INFO : PROGRESS: at 58.10% examples, 67307 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:42,557 : INFO : PROGRESS: at 58.84% examples, 67320 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:43,628 : INFO : PROGRESS: at 59.64% examples, 67374 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:22:44,723 : INFO : PROGRESS: at 60.41% examples, 67349 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:45,837 : INFO : PROGRESS: at 61.07% examples, 67303 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:46,921 : INFO : PROGRESS: at 61.86% examples, 67384 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:47,964 : INFO : PROGRESS: at 62.69% examples, 67358 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:48,997 : INFO : PROGRESS: at 63.27% examples, 67284 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:50,014 : INFO : PROGRESS: at 63.89% examples, 67378 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:51,030 : INFO : PROGRESS: at 64.64% examples, 67393 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:52,037 : INFO : PROGRESS: at 65.54% examples, 67414 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:53,149 : INFO : PROGRESS: at 66.30% examples, 67365 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:54,253 : INFO : PROGRESS: at 67.02% examples, 67377 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:55,326 : INFO : PROGRESS: at 67.80% examples, 67273 words/s, in_qsize 0, out_qsize 1\n",
      "2018-01-08 01:22:56,362 : INFO : PROGRESS: at 68.31% examples, 67357 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:57,507 : INFO : PROGRESS: at 68.86% examples, 67371 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:58,604 : INFO : PROGRESS: at 69.62% examples, 67422 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:22:59,746 : INFO : PROGRESS: at 70.50% examples, 67346 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:00,809 : INFO : PROGRESS: at 71.32% examples, 67411 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:01,992 : INFO : PROGRESS: at 72.03% examples, 67316 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:03,097 : INFO : PROGRESS: at 73.11% examples, 67415 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:04,200 : INFO : PROGRESS: at 73.77% examples, 67370 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:05,236 : INFO : PROGRESS: at 74.45% examples, 67383 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:06,237 : INFO : PROGRESS: at 75.27% examples, 67323 words/s, in_qsize 0, out_qsize 1\n",
      "2018-01-08 01:23:07,272 : INFO : PROGRESS: at 75.97% examples, 67329 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:08,409 : INFO : PROGRESS: at 76.66% examples, 67342 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:09,437 : INFO : PROGRESS: at 77.68% examples, 67409 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:10,513 : INFO : PROGRESS: at 78.35% examples, 67394 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:11,621 : INFO : PROGRESS: at 79.06% examples, 67427 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:12,689 : INFO : PROGRESS: at 79.89% examples, 67403 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:23:13,821 : INFO : PROGRESS: at 80.55% examples, 67396 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:14,792 : INFO : PROGRESS: at 81.19% examples, 67423 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:15,806 : INFO : PROGRESS: at 81.91% examples, 67371 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:16,905 : INFO : PROGRESS: at 82.78% examples, 67403 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:18,109 : INFO : PROGRESS: at 83.54% examples, 67397 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:19,217 : INFO : PROGRESS: at 84.14% examples, 67405 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:20,362 : INFO : PROGRESS: at 85.11% examples, 67407 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:21,443 : INFO : PROGRESS: at 85.90% examples, 67380 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:22,521 : INFO : PROGRESS: at 86.62% examples, 67351 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:23,525 : INFO : PROGRESS: at 87.45% examples, 67425 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:24,595 : INFO : PROGRESS: at 88.06% examples, 67415 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:25,661 : INFO : PROGRESS: at 88.53% examples, 67457 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:26,728 : INFO : PROGRESS: at 89.19% examples, 67447 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:27,761 : INFO : PROGRESS: at 90.00% examples, 67462 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:28,831 : INFO : PROGRESS: at 90.82% examples, 67436 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:30,026 : INFO : PROGRESS: at 91.58% examples, 67417 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:31,081 : INFO : PROGRESS: at 92.40% examples, 67405 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:32,117 : INFO : PROGRESS: at 93.22% examples, 67406 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:33,309 : INFO : PROGRESS: at 93.93% examples, 67385 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:34,465 : INFO : PROGRESS: at 94.81% examples, 67385 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:35,533 : INFO : PROGRESS: at 95.65% examples, 67368 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:36,692 : INFO : PROGRESS: at 96.32% examples, 67369 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:37,737 : INFO : PROGRESS: at 97.21% examples, 67415 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:38,814 : INFO : PROGRESS: at 98.01% examples, 67402 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:39,869 : INFO : PROGRESS: at 98.68% examples, 67413 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:40,992 : INFO : PROGRESS: at 99.33% examples, 67367 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:23:41,410 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-01-08 01:23:41,484 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-01-08 01:23:41,509 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-01-08 01:23:41,510 : INFO : training on 12323310 raw words (9714152 effective words) took 144.0s, 67462 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Time: 154.461s.\n"
     ]
    }
   ],
   "source": [
    "# Process w2v with model of n dimensions and min doc-term freq as min_df\n",
    "t1 = time.time()\n",
    "w2v_model = Word2Vec(docgen, \n",
    "                     sg=1, \n",
    "                     min_count=min_df,\n",
    "                     max_vocab_size=max_vocab_size,\n",
    "                     size=dim_size)                 # size: the word vector dimensionality (same as max_vocal_size?)\n",
    "print \"- Time: %0.3fs.\" % (time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:28:28,022 : INFO : collecting all words and their counts\n",
      "2018-01-08 01:28:28,029 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Tokenizing the documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:28:32,152 : INFO : PROGRESS: at sentence #10000, processed 1053228 words, keeping 29264 word types\n",
      "2018-01-08 01:28:36,158 : INFO : PROGRESS: at sentence #20000, processed 2076095 words, keeping 41027 word types\n",
      "2018-01-08 01:28:37,700 : INFO : collected 44932 word types from a corpus of 2464662 raw words and 24015 sentences\n",
      "2018-01-08 01:28:37,701 : INFO : Loading a fresh vocabulary\n",
      "2018-01-08 01:28:37,733 : INFO : min_count=40 retains 5908 unique words (13% of original 44932, drops 39024)\n",
      "2018-01-08 01:28:37,734 : INFO : min_count=40 leaves 2277822 word corpus (92% of original 2464662, drops 186840)\n",
      "2018-01-08 01:28:37,826 : INFO : deleting the raw counts dictionary of 44932 items\n",
      "2018-01-08 01:28:37,833 : INFO : sample=0.001 downsamples 8 most-common words\n",
      "2018-01-08 01:28:37,834 : INFO : downsampling leaves estimated 2268460 word corpus (99.6% of prior 2277822)\n",
      "2018-01-08 01:28:37,837 : INFO : estimated required memory for 5908 words and 300 dimensions: 17133200 bytes\n",
      "2018-01-08 01:28:37,852 : INFO : resetting layer weights\n",
      "2018-01-08 01:28:37,932 : INFO : training model with 4 workers on 5908 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:28:38,991 : INFO : PROGRESS: at 1.16% examples, 139101 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:40,020 : INFO : PROGRESS: at 2.57% examples, 140059 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:41,050 : INFO : PROGRESS: at 3.73% examples, 141366 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:42,055 : INFO : PROGRESS: at 5.11% examples, 142430 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:43,058 : INFO : PROGRESS: at 6.49% examples, 142848 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:44,077 : INFO : PROGRESS: at 7.82% examples, 142707 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:45,122 : INFO : PROGRESS: at 8.67% examples, 143945 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:46,135 : INFO : PROGRESS: at 10.00% examples, 143976 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:47,184 : INFO : PROGRESS: at 11.42% examples, 144430 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:48,208 : INFO : PROGRESS: at 12.90% examples, 144234 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:49,230 : INFO : PROGRESS: at 14.08% examples, 144139 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:50,248 : INFO : PROGRESS: at 15.58% examples, 144038 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:51,252 : INFO : PROGRESS: at 16.71% examples, 144116 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:52,270 : INFO : PROGRESS: at 18.17% examples, 143998 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:53,283 : INFO : PROGRESS: at 19.33% examples, 144023 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:28:54,297 : INFO : PROGRESS: at 20.66% examples, 143985 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:55,327 : INFO : PROGRESS: at 21.95% examples, 143796 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:56,339 : INFO : PROGRESS: at 23.27% examples, 143811 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:57,365 : INFO : PROGRESS: at 24.45% examples, 143879 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:58,402 : INFO : PROGRESS: at 25.93% examples, 143669 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:28:59,429 : INFO : PROGRESS: at 27.23% examples, 143532 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:00,488 : INFO : PROGRESS: at 28.33% examples, 143728 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:01,494 : INFO : PROGRESS: at 29.37% examples, 143850 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:02,505 : INFO : PROGRESS: at 30.78% examples, 143510 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:03,525 : INFO : PROGRESS: at 32.03% examples, 143507 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:04,544 : INFO : PROGRESS: at 33.49% examples, 143459 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:05,551 : INFO : PROGRESS: at 34.75% examples, 143514 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:06,590 : INFO : PROGRESS: at 36.08% examples, 143419 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:07,627 : INFO : PROGRESS: at 37.48% examples, 143272 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:08,643 : INFO : PROGRESS: at 38.72% examples, 143307 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:09,662 : INFO : PROGRESS: at 40.09% examples, 143283 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:29:10,663 : INFO : PROGRESS: at 41.19% examples, 143369 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:11,701 : INFO : PROGRESS: at 42.65% examples, 143256 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:12,727 : INFO : PROGRESS: at 43.81% examples, 143312 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:13,753 : INFO : PROGRESS: at 45.23% examples, 143294 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:14,814 : INFO : PROGRESS: at 46.62% examples, 143347 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:15,853 : INFO : PROGRESS: at 47.92% examples, 143257 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:16,907 : INFO : PROGRESS: at 48.82% examples, 143434 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:17,924 : INFO : PROGRESS: at 50.19% examples, 143454 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:18,919 : INFO : PROGRESS: at 51.53% examples, 143514 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:19,964 : INFO : PROGRESS: at 52.99% examples, 143414 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:20,976 : INFO : PROGRESS: at 54.16% examples, 143446 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:22,009 : INFO : PROGRESS: at 55.65% examples, 143373 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:23,018 : INFO : PROGRESS: at 56.83% examples, 143418 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:24,037 : INFO : PROGRESS: at 58.26% examples, 143382 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:25,043 : INFO : PROGRESS: at 59.44% examples, 143427 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:29:26,083 : INFO : PROGRESS: at 60.75% examples, 143344 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:27,084 : INFO : PROGRESS: at 62.03% examples, 143371 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:28,102 : INFO : PROGRESS: at 63.36% examples, 143386 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:29,125 : INFO : PROGRESS: at 64.54% examples, 143413 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:30,139 : INFO : PROGRESS: at 66.03% examples, 143403 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:31,156 : INFO : PROGRESS: at 67.30% examples, 143381 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:32,212 : INFO : PROGRESS: at 68.35% examples, 143478 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:33,217 : INFO : PROGRESS: at 69.45% examples, 143533 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:34,236 : INFO : PROGRESS: at 70.94% examples, 143536 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:35,276 : INFO : PROGRESS: at 72.24% examples, 143474 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:36,280 : INFO : PROGRESS: at 73.61% examples, 143493 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:37,321 : INFO : PROGRESS: at 74.95% examples, 143445 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:38,326 : INFO : PROGRESS: at 76.18% examples, 143475 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:39,355 : INFO : PROGRESS: at 77.68% examples, 143422 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:40,419 : INFO : PROGRESS: at 78.92% examples, 143475 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:29:41,433 : INFO : PROGRESS: at 80.31% examples, 143473 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:42,489 : INFO : PROGRESS: at 81.52% examples, 143533 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:43,500 : INFO : PROGRESS: at 82.92% examples, 143537 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:44,525 : INFO : PROGRESS: at 84.08% examples, 143572 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:45,549 : INFO : PROGRESS: at 85.59% examples, 143546 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:46,551 : INFO : PROGRESS: at 86.84% examples, 143560 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:47,559 : INFO : PROGRESS: at 88.06% examples, 143591 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:48,568 : INFO : PROGRESS: at 88.97% examples, 143629 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:49,589 : INFO : PROGRESS: at 90.38% examples, 143619 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:50,604 : INFO : PROGRESS: at 91.65% examples, 143630 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:51,629 : INFO : PROGRESS: at 93.15% examples, 143601 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:52,634 : INFO : PROGRESS: at 94.36% examples, 143633 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:53,649 : INFO : PROGRESS: at 95.80% examples, 143620 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:54,711 : INFO : PROGRESS: at 97.12% examples, 143645 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:55,721 : INFO : PROGRESS: at 98.46% examples, 143656 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:56,739 : INFO : PROGRESS: at 99.75% examples, 143651 words/s, in_qsize 0, out_qsize 0\n",
      "2018-01-08 01:29:56,861 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-01-08 01:29:56,865 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-01-08 01:29:56,877 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-01-08 01:29:56,887 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-01-08 01:29:56,888 : INFO : training on 12323310 raw words (11342040 effective words) took 78.9s, 143665 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Time: 88.873s.\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/c/word2vec-nlp-tutorial#part-2-word-vectors\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "print \"Training model...\"\n",
    "t1 = time.time()\n",
    "# model = word2vec.Word2Vec(docs, workers=num_workers, \\\n",
    "w2v_model = Word2Vec(docgen, \n",
    "                     workers=num_workers, \n",
    "                     size=num_features, \n",
    "                     min_count=min_word_count, \n",
    "                     window=context, \n",
    "                     sample=downsampling)\n",
    "print \"- Time: %0.3fs.\" % (time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:31:10,244 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:31:12,874 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
      "2018-01-08 01:31:12,879 : INFO : not storing attribute syn0norm\n",
      "2018-01-08 01:31:12,881 : INFO : not storing attribute cum_table\n",
      "2018-01-08 01:31:12,936 : INFO : saved 300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'specialist'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab\n",
    "model.doesnt_match(\"bar kitchen specialist deli\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:46:40,213 : INFO : loading projection weights from ../model/GoogleNews-vectors-negative300.bin\n",
      "2018-01-08 01:47:41,886 : INFO : loaded (3000000, 300) matrix from ../model/GoogleNews-vectors-negative300.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Time: 64.4013569355\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "goog_news_w2v_model = KeyedVectors.load_word2vec_format('../model/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "print '- Time: %s' % (time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 01:48:05,708 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n",
      "[(u'tavern', 0.5487228631973267), (u'bartender', 0.5428971648216248), (u'restaurant', 0.5355651378631592), (u'pub', 0.5140328407287598), (u'bars', 0.5019227266311646), (u'Bar', 0.5018932819366455), (u'restuarant', 0.4939461350440979), (u'caf\\xe9', 0.48689597845077515), (u'cafe', 0.48496049642562866), (u'drinkery', 0.4809538424015045)]\n",
      "- Time: 6.96264314651\n"
     ]
    }
   ],
   "source": [
    "print len(goog_news_w2v_model.vocab)\n",
    "t1 = time.time()\n",
    "print goog_news_w2v_model.most_similar(positive=['server', 'bar'], negative=['CPU'], topn=10)\n",
    "print '- Time: %s' % (time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:1316: UserWarning: findfont: Font family [u'xkcd', u'Humor Sans', u'Comic Sans MS'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAEbCAYAAAB3DOvsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6DgYMcYYEx0HI8YYY6LjYMQYY0x0/wEpiuuh6dpNeQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdaeba5b490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def plot_words(words):\n",
    "    word_vecs = [goog_news_w2v_model[word] for word in words]\n",
    "    pca = PCA(n_components=2)\n",
    "\n",
    "    columns = [\"Component1\",\"Component2\"]\n",
    "    df = pd.DataFrame(pca.fit_transform(word_vecs), columns=columns, index=words)\n",
    "    def annotate_df(row):  \n",
    "        ax.annotate(row.name, list(row.values),\n",
    "                    xytext=(10,-5), \n",
    "                    textcoords='offset points',\n",
    "                    size=18, \n",
    "                    color='darkslategrey')\n",
    "    with plt.xkcd():\n",
    "        ax = df.plot(kind=\"scatter\",x='Component1', y='Component2',)\n",
    "        _ = df.apply(annotate_df, axis=1)\n",
    "        \n",
    "words= ['king','queen','prince','princess', 'uncle', 'aunt']\n",
    "words= ['mail','restaurant','cpu','server', 'bar', 'deli']\n",
    "plot_words(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Time: 23.8291900158\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Analzye/preprocess/tokenize the words in each doc\n",
    "#\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "sw = topic_model.get_stop_words()\n",
    "pattern = re.compile(topic_model.get_token_pattern())\n",
    "lemmer = WordNetLemmatizer()\n",
    "new_docs = []\n",
    "t1 = time.time()\n",
    "for doc in docs:\n",
    "    words = doc.split()\n",
    "    d = [lemmer.lemmatize(w) for w in list(set(analyzer(doc)) - set(sw)) if pattern.match(w)]\n",
    "#     d = [word for word in words if len(word) > 2 and word.isalnum() is word not in ]\n",
    "    new_docs.append(d)\n",
    "print '- Time: %s' % (time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are seeking baristas for Le Marais Bistro &amp; Bakery, located at 2066/68 Chestnut Street in San Francisco's Marina District. We offer training and support from Stumptown Coffee Roasters. Part-time and full-time positions available.\n",
      "\n",
      "We are looking for motivated and enthusiastic individuals who have a genuine sense of hospitality, and a love and knowledge of French food and baked items, coffee, wine and beer. All positions offer amazing tips and the opportunity to work with a great team, along with appreciative customers and a welcoming atmosphere.\n",
      "\n",
      "Candidates should:\n",
      "Excel in customer service\n",
      "Be familiar with the food service health codes\n",
      "Work well in a team setting\n",
      "Enjoy working in a fast-paced environment\n",
      "\n",
      "Influenced by classic French traditions and a farm-to-table philosophy, Le Marais Bistro &amp; Bakery in San Francisco's Marina District relies on artisanal techniques and a passion for ingredients that are grown locally and responsibly. Le Marais been hailed as one of best bakeries in San Francisco by Cond Nast Traveler, San Francisco Magazine, San Francisco Chronicle, Forbes' Travel, Fodor's Travel, EaterSF, Tablehopper, 7X7, Tasting Table, SF Bay Guardian (Best of the Bay 2013), Marina Times, and The Wall Street Journal. The San Francisco Chronicle recently reported, \"As Bar Tartine and Le Marais attest, the bakery-restaurant is on the rise in San Francisco. It makes sense: We love handmade breads and pastries. We also adore tiny, chef-driven restaurants.\"\n",
      "\n",
      "[u'baristas', u'marais', u'bistro', u'amp', u'bakery', u'located', u'chestnut', u'marina', u'district', u'support', u'stumptown', u'coffee', u'roasters', u'positions', u'motivated', u'enthusiastic', u'genuine', u'sense', u'hospitality', u'french', u'food', u'baked', u'items', u'coffee', u'wine', u'beer', u'positions', u'amazing', u'tips', u'appreciative', u'customers', u'welcoming', u'atmosphere', u'candidates', u'excel', u'customer', u'service', u'familiar', u'food', u'service', u'codes', u'setting', u'enjoy', u'fast', u'paced', u'environment', u'influenced', u'classic', u'french', u'traditions', u'farm', u'table', u'philosophy', u'marais', u'bistro', u'amp', u'bakery', u'marina', u'district', u'relies', u'artisanal', u'techniques', u'passion', u'ingredients', u'grown', u'locally', u'responsibly', u'marais', u'hailed', u'bakeries', u'cond\\xe3', u'nast', u'traveler', u'magazine', u'chronicle', u'forbes', u'travel', u'fodor', u'travel', u'eatersf', u'tablehopper', u'tasting', u'table', u'bay', u'guardian', u'bay', u'marina', u'times', u'wall', u'journal', u'chronicle', u'recently', u'reported', u'bar', u'tartine', u'marais', u'attest', u'bakery', u'restaurant', u'rise', u'makes', u'sense', u'handmade', u'breads', u'pastries', u'adore', u'tiny', u'chef', u'driven', u'restaurants']\n",
      "(24015,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'atmosphere',\n",
       " u'tradition',\n",
       " u'excel',\n",
       " u'environment',\n",
       " u'forbes',\n",
       " u'candidate',\n",
       " u'artisanal',\n",
       " u'coffee',\n",
       " u'motivated',\n",
       " u'food',\n",
       " u'familiar',\n",
       " u'rise',\n",
       " u'hailed',\n",
       " u'cond\\xe3',\n",
       " u'amp',\n",
       " u'baristas',\n",
       " u'bar',\n",
       " u'position',\n",
       " u'bay',\n",
       " u'restaurant',\n",
       " u'enjoy',\n",
       " u'attest',\n",
       " u'chef',\n",
       " u'table',\n",
       " u'technique',\n",
       " u'appreciative',\n",
       " u'passion',\n",
       " u'tip',\n",
       " u'bistro',\n",
       " u'recently',\n",
       " u'guardian',\n",
       " u'journal',\n",
       " u'french',\n",
       " u'reported',\n",
       " u'marina',\n",
       " u'bakery',\n",
       " u'district',\n",
       " u'restaurant',\n",
       " u'item',\n",
       " u'time',\n",
       " u'magazine',\n",
       " u'hospitality',\n",
       " u'make',\n",
       " u'pastry',\n",
       " u'wall',\n",
       " u'tartine',\n",
       " u'tiny',\n",
       " u'traveler',\n",
       " u'stumptown',\n",
       " u'service',\n",
       " u'tasting',\n",
       " u'support',\n",
       " u'locally',\n",
       " u'fast',\n",
       " u'beer',\n",
       " u'chestnut',\n",
       " u'customer',\n",
       " u'welcoming',\n",
       " u'chronicle',\n",
       " u'tablehopper',\n",
       " u'adore',\n",
       " u'classic',\n",
       " u'customer',\n",
       " u'sense',\n",
       " u'grown',\n",
       " u'influenced',\n",
       " u'code',\n",
       " u'genuine',\n",
       " u'ingredient',\n",
       " u'travel',\n",
       " u'marais',\n",
       " u'handmade',\n",
       " u'located',\n",
       " u'amazing',\n",
       " u'setting',\n",
       " u'responsibly',\n",
       " u'farm',\n",
       " u'philosophy',\n",
       " u'driven',\n",
       " u'fodor',\n",
       " u'relies',\n",
       " u'bread',\n",
       " u'nast',\n",
       " u'roaster',\n",
       " u'enthusiastic',\n",
       " u'bakery',\n",
       " u'eatersf',\n",
       " u'baked',\n",
       " u'paced',\n",
       " u'wine']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print docs[1]\n",
    "print analyzer(docs[1])\n",
    "new_docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45,)\n",
      "(90,)\n",
      "(16,)\n",
      "(11,)\n",
      "(23,)\n",
      "(70,)\n",
      "(10,)\n",
      "(13,)\n",
      "(18,)\n",
      "(9,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print np.array(new_docs[i]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the documents...\n"
     ]
    }
   ],
   "source": [
    "words = [word for word in docgen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "We are seeking baristas for Le Marais Bistro &amp; Bakery, located at 2066/68 Chestnut Street in San Francisco's Marina District. We offer training and support from Stumptown Coffee Roasters. Part-time and full-time positions available.\n",
      "\n",
      "We are looking for motivated and enthusiastic individuals who have a genuine sense of hospitality, and a love and knowledge of French food and baked items, coffee, wine and beer. All positions offer amazing tips and the opportunity to work with a great team, along with appreciative customers and a welcoming atmosphere.\n",
      "\n",
      "Candidates should:\n",
      "Excel in customer service\n",
      "Be familiar with the food service health codes\n",
      "Work well in a team setting\n",
      "Enjoy working in a fast-paced environment\n",
      "\n",
      "Influenced by classic French traditions and a farm-to-table philosophy, Le Marais Bistro &amp; Bakery in San Francisco's Marina District relies on artisanal techniques and a passion for ingredients that are grown locally and responsibly. Le Marais been hailed as one of best bakeries in San Francisco by Cond Nast Traveler, San Francisco Magazine, San Francisco Chronicle, Forbes' Travel, Fodor's Travel, EaterSF, Tablehopper, 7X7, Tasting Table, SF Bay Guardian (Best of the Bay 2013), Marina Times, and The Wall Street Journal. The San Francisco Chronicle recently reported, \"As Bar Tartine and Le Marais attest, the bakery-restaurant is on the rise in San Francisco. It makes sense: We love handmade breads and pastries. We also adore tiny, chef-driven restaurants.\"\n",
      "\n",
      "[u'atmosphere', u'traditions', u'excel', u'environment', u'forbes', u'candidates', u'artisanal', u'coffee', u'motivated', u'food', u'familiar', u'rise', u'hailed', u'cond\\xe3', u'amp', u'baristas', u'bar', u'positions', u'bay', u'restaurants', u'enjoy', u'attest', u'chef', u'table', u'techniques', u'appreciative', u'passion', u'tips', u'bistro', u'recently', u'guardian', u'journal', u'french', u'reported', u'marina', u'bakeries', u'district', u'restaurant', u'items', u'times', u'magazine', u'hospitality', u'makes', u'pastries', u'wall', u'tartine', u'tiny', u'traveler', u'stumptown', u'service', u'tasting', u'support', u'locally', u'fast', u'beer', u'chestnut', u'customer', u'welcoming', u'chronicle', u'tablehopper', u'adore', u'classic', u'customers', u'sense', u'grown', u'influenced', u'codes', u'genuine', u'ingredients', u'travel', u'marais', u'handmade', u'located', u'amazing', u'setting', u'responsibly', u'farm', u'philosophy', u'driven', u'fodor', u'relies', u'breads', u'nast', u'roasters', u'enthusiastic', u'bakery', u'eatersf', u'baked', u'paced', u'wine']\n"
     ]
    }
   ],
   "source": [
    "print len(words[1])\n",
    "print docs[1]\n",
    "print words[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----\n",
    "# Doc2Vec\n",
    "# ----\n",
    "In word2vec, the parameter continuous bag of words (cbow) and skip-gram (sg); \n",
    "in the doc2vec architecture, the corresponding algorithms are distributed memory (dm) and distributed bag of words (dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 02:42:09,071 : INFO : collecting all words and their counts\n",
      "2018-01-08 02:42:09,072 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-01-08 02:42:09,382 : INFO : PROGRESS: at example #10000, processed 1053349 words (3423721/s), 26006 word types, 10000 tags\n",
      "2018-01-08 02:42:09,688 : INFO : PROGRESS: at example #20000, processed 2076333 words (3357149/s), 36904 word types, 20000 tags\n",
      "2018-01-08 02:42:09,808 : INFO : collected 40557 word types and 24015 unique tags from a corpus of 24015 examples and 2464929 words\n",
      "2018-01-08 02:42:09,809 : INFO : Loading a fresh vocabulary\n",
      "2018-01-08 02:42:09,845 : INFO : min_count=10 retains 9937 unique words (24% of original 40557, drops 30620)\n",
      "2018-01-08 02:42:09,846 : INFO : min_count=10 leaves 2395422 word corpus (97% of original 2464929, drops 69507)\n",
      "2018-01-08 02:42:09,873 : INFO : deleting the raw counts dictionary of 40557 items\n",
      "2018-01-08 02:42:09,875 : INFO : sample=0.001 downsamples 12 most-common words\n",
      "2018-01-08 02:42:09,877 : INFO : downsampling leaves estimated 2375019 word corpus (99.1% of prior 2395422)\n",
      "2018-01-08 02:42:09,878 : INFO : estimated required memory for 9937 words and 100 dimensions: 27327100 bytes\n",
      "2018-01-08 02:42:09,908 : INFO : resetting layer weights\n",
      "2018-01-08 02:42:10,271 : INFO : training model with 4 workers on 9937 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=300\n",
      "2018-01-08 02:42:11,280 : INFO : PROGRESS: at 0.71% examples, 96163 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:12,302 : INFO : PROGRESS: at 1.53% examples, 100328 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:42:13,387 : INFO : PROGRESS: at 2.73% examples, 105483 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:14,412 : INFO : PROGRESS: at 3.59% examples, 107513 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:15,421 : INFO : PROGRESS: at 4.49% examples, 109096 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:16,590 : INFO : PROGRESS: at 5.83% examples, 110256 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:17,659 : INFO : PROGRESS: at 6.84% examples, 111244 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:18,690 : INFO : PROGRESS: at 7.81% examples, 110193 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:19,742 : INFO : PROGRESS: at 8.32% examples, 108277 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:42:20,782 : INFO : PROGRESS: at 8.90% examples, 106701 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:42:21,789 : INFO : PROGRESS: at 10.00% examples, 108297 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:22,882 : INFO : PROGRESS: at 11.17% examples, 108847 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:23,997 : INFO : PROGRESS: at 12.20% examples, 109152 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:25,111 : INFO : PROGRESS: at 13.46% examples, 110065 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:26,120 : INFO : PROGRESS: at 14.25% examples, 109795 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:42:27,124 : INFO : PROGRESS: at 15.49% examples, 110653 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:42:28,138 : INFO : PROGRESS: at 16.19% examples, 109780 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:42:29,226 : INFO : PROGRESS: at 17.32% examples, 110064 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:30,253 : INFO : PROGRESS: at 18.34% examples, 110211 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:31,321 : INFO : PROGRESS: at 19.18% examples, 110149 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:42:32,394 : INFO : PROGRESS: at 20.33% examples, 110431 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:33,402 : INFO : PROGRESS: at 21.14% examples, 110205 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:34,452 : INFO : PROGRESS: at 22.23% examples, 110579 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:35,627 : INFO : PROGRESS: at 23.29% examples, 110417 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:36,641 : INFO : PROGRESS: at 24.11% examples, 110608 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:42:37,647 : INFO : PROGRESS: at 25.37% examples, 111114 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:38,680 : INFO : PROGRESS: at 26.44% examples, 111477 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:39,737 : INFO : PROGRESS: at 27.30% examples, 111083 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:42:40,741 : INFO : PROGRESS: at 28.06% examples, 110580 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:41,976 : INFO : PROGRESS: at 28.56% examples, 109630 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:43,025 : INFO : PROGRESS: at 29.53% examples, 109955 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:44,064 : INFO : PROGRESS: at 30.78% examples, 110305 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:45,079 : INFO : PROGRESS: at 31.70% examples, 110424 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:46,096 : INFO : PROGRESS: at 32.94% examples, 110781 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:47,249 : INFO : PROGRESS: at 33.83% examples, 110452 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:48,327 : INFO : PROGRESS: at 34.95% examples, 110627 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:42:49,461 : INFO : PROGRESS: at 36.01% examples, 110627 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:50,463 : INFO : PROGRESS: at 36.96% examples, 110745 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:51,485 : INFO : PROGRESS: at 38.04% examples, 110805 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:52,534 : INFO : PROGRESS: at 38.87% examples, 110593 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:42:53,582 : INFO : PROGRESS: at 39.99% examples, 110780 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:42:54,636 : INFO : PROGRESS: at 40.86% examples, 110756 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:42:55,791 : INFO : PROGRESS: at 41.91% examples, 110706 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:42:56,925 : INFO : PROGRESS: at 42.99% examples, 110725 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:42:57,941 : INFO : PROGRESS: at 43.86% examples, 110826 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:42:58,941 : INFO : PROGRESS: at 44.90% examples, 110938 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:42:59,964 : INFO : PROGRESS: at 46.17% examples, 111356 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:43:00,975 : INFO : PROGRESS: at 47.07% examples, 111214 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:43:02,009 : INFO : PROGRESS: at 47.95% examples, 111059 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:43:03,293 : INFO : PROGRESS: at 48.42% examples, 110195 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:43:04,322 : INFO : PROGRESS: at 49.26% examples, 110410 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:43:05,332 : INFO : PROGRESS: at 50.47% examples, 110666 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:43:06,346 : INFO : PROGRESS: at 51.42% examples, 110730 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:43:07,383 : INFO : PROGRESS: at 52.50% examples, 110748 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:43:08,453 : INFO : PROGRESS: at 53.59% examples, 110869 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:43:09,590 : INFO : PROGRESS: at 54.52% examples, 110723 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:43:10,709 : INFO : PROGRESS: at 55.80% examples, 110884 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:43:11,818 : INFO : PROGRESS: at 56.63% examples, 110763 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:43:12,822 : INFO : PROGRESS: at 57.89% examples, 110985 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:43:13,830 : INFO : PROGRESS: at 58.68% examples, 110899 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:43:14,901 : INFO : PROGRESS: at 59.74% examples, 110991 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:43:15,912 : INFO : PROGRESS: at 60.60% examples, 110914 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:43:17,071 : INFO : PROGRESS: at 61.47% examples, 110709 words/s, in_qsize 7, out_qsize 0\n",
      "2018-01-08 02:43:18,094 : INFO : PROGRESS: at 62.68% examples, 110881 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:43:19,150 : INFO : PROGRESS: at 63.62% examples, 111016 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:43:20,253 : INFO : PROGRESS: at 64.54% examples, 110929 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-08 02:43:21,262 : INFO : PROGRESS: at 65.87% examples, 111250 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:43:22,291 : INFO : PROGRESS: at 66.80% examples, 111263 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:43:23,354 : INFO : PROGRESS: at 67.83% examples, 111220 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:43:24,551 : INFO : PROGRESS: at 68.33% examples, 110730 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:43:25,627 : INFO : PROGRESS: at 69.01% examples, 110566 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:43:26,689 : INFO : PROGRESS: at 70.13% examples, 110676 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:43:27,720 : INFO : PROGRESS: at 71.27% examples, 110828 words/s, in_qsize 8, out_qsize 0\n",
      "2018-01-08 02:43:28,772 : INFO : PROGRESS: at 72.24% examples, 110817 words/s, in_qsize 8, out_qsize 0\n"
     ]
    }
   ],
   "source": [
    "# Doc2Vec\n",
    "# https://github.com/olafmaas/hackdelft/blob/master/hackdelft/doc2vec/train_doc2vec.py\n",
    "\n",
    "# create A Labeled sentence for each toeknized doc in the preprocessed doc set 'new_docs'\n",
    "# document = LabeledSentence(words=['some', 'words', 'here'], tags=['SENT_1']) \n",
    "labeled_docs = []\n",
    "for i in range(len(new_docs)):\n",
    "    tag_name = 'SENT_%s' % i\n",
    "    labeled_doc = LabeledSentence(words=new_docs[i], tags=[tag_name])\n",
    "    labeled_docs.append(labeled_doc)\n",
    "model = Doc2Vec(labeled_docs, size = 100, window = 300, min_count = 10, workers=4)\n",
    "\n",
    "t1 = time.time()\n",
    "d2v_model = Doc2Vec(size=100, dbow_words= 1, dm=0, iter=1,  window=5, seed=1337, \n",
    "                min_count=5, workers=4, alpha=0.025, min_alpha=0.025)\n",
    "d2v_model.build_vocab(new_docs)\n",
    "# w2v_model = gensim.models.Word2Vec(docgen, sg=1, max_vocab_size=max_vocab_size,\n",
    "#                                    size=dim_size, min_count=min_df)\n",
    "print \"- Time: %0.3fs.\" % (time.time() - t1)\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(\"epoch \"+str(epoch))\n",
    "    d2v_model.train(documents, total_examples=count, epochs=1)\n",
    "    d2v_model.save('cyber-trend-index-dataset.model')\n",
    "    d2v_model.alpha -= 0.002  # decrease the learning rate\n",
    "    d2v_model.min_alpha = d2v_model.alpha  # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://medium.com/@klintcho/doc2vec-tutorial-using-gensim-ab3ac03d3a1\n",
    "# from gensim.models.doc2vec import LabeledSentence\n",
    "# ls = LabeledSentence(l)\n",
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, doc_list):\n",
    "       #self.labels_list = labels_list\n",
    "       self.doc_list = doc_list\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "            words = doc.split()\n",
    "            word_list = [word for word in words if len(word) > 2 and word.isalnum()]\n",
    "            yield LabeledSentence(words=word_list,tags=str(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-27 22:12:26,915 : INFO : collecting all words and their counts\n",
      "2017-12-27 22:12:26,921 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2017-12-27 22:12:28,036 : INFO : PROGRESS: at example #10000, processed 1923371 words (1728701/s), 33635 word types, 10 tags\n",
      "2017-12-27 22:12:29,163 : INFO : PROGRESS: at example #20000, processed 3782006 words (1650302/s), 45752 word types, 10 tags\n",
      "2017-12-27 22:12:29,596 : INFO : collected 49815 word types and 10 unique tags from a corpus of 24015 examples and 4487961 words\n",
      "2017-12-27 22:12:29,597 : INFO : Loading a fresh vocabulary\n",
      "2017-12-27 22:12:29,657 : INFO : min_count=5 retains 20923 unique words (42% of original 49815, drops 28892)\n",
      "2017-12-27 22:12:29,658 : INFO : min_count=5 leaves 4437350 word corpus (98% of original 4487961, drops 50611)\n",
      "2017-12-27 22:12:29,765 : INFO : deleting the raw counts dictionary of 49815 items\n",
      "2017-12-27 22:12:29,770 : INFO : sample=0.001 downsamples 28 most-common words\n",
      "2017-12-27 22:12:29,772 : INFO : downsampling leaves estimated 3699678 word corpus (83.4% of prior 4437350)\n",
      "2017-12-27 22:12:29,776 : INFO : estimated required memory for 20923 words and 300 dimensions: 60690700 bytes\n",
      "2017-12-27 22:12:29,832 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "lls = LabeledLineSentence(docs)\n",
    "\n",
    "d2v_model = Doc2Vec(size=300, window=10, min_count=5, workers=11,alpha=0.025, min_alpha=0.025) # use fixed learning rate\n",
    "\n",
    "d2v_model.build_vocab(lls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-27 22:42:46,974 : INFO : training model with 11 workers on 20923 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You must specify either total_examples or total_words, for proper alpha and progress calculations. The usual value is total_examples=model.corpus_count.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-d59ae73c1980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# https://github.com/RaRe-Technologies/gensim/releases/tag/2.0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m0.002\u001b[0m \u001b[0;31m# decrease the learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;31m# fix the learning rate, no deca\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda2/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_words\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtotal_examples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             raise ValueError(\n\u001b[0;32m--> 940\u001b[0;31m                 \u001b[0;34m\"You must specify either total_examples or total_words, for proper alpha and progress calculations. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;34m\"The usual value is total_examples=model.corpus_count.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: You must specify either total_examples or total_words, for proper alpha and progress calculations. The usual value is total_examples=model.corpus_count."
     ]
    }
   ],
   "source": [
    "# https://github.com/RaRe-Technologies/gensim/releases/tag/2.0.0\n",
    "for epoch in range(10):\n",
    "    d2v_model.train(ls)\n",
    "    d2v_model.alpha -= 0.002 # decrease the learning rate\n",
    "    d2v_model.min_alpha = d2v_model.alpha # fix the learning rate, no deca\n",
    "    d2v_model.train(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f4d5d0c0671b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
